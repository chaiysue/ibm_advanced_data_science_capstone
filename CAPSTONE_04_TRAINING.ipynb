{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5155b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a968d837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d28b019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2777fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab6ed9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [\"text\",\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "848d8f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chaiy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chaiy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f6e1c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e4d49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "for par in data[\"text\"].values:\n",
    "    tmp = []\n",
    "    sentences = nltk.sent_tokenize(par)\n",
    "    for sent in sentences:\n",
    "        sent = sent.lower()\n",
    "        tokens = tokenizer.tokenize(sent)\n",
    "        filtered_words = [w.strip() for w in tokens if w not in stop_words and len(w) > 1]\n",
    "        tmp.extend(filtered_words)\n",
    "    X.append(tmp)\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cbb86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2d9d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimension of vectors we are generating\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "#Creating Word Vectors by Word2Vec Method (takes time...)\n",
    "w2v_model = gensim.models.Word2Vec(sentences=X, size=EMBEDDING_DIM, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9f218e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110688"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vocab size\n",
    "len(w2v_model.wv.vocab)\n",
    "\n",
    "#We have now represented each of 122248 words by a 100dim vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58cf4dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00890209e-03, -1.99008791e-05, -1.24007715e-02,  2.54451334e-02,\n",
       "       -3.86230238e-02, -1.35915424e-03, -1.14998000e-03,  2.46495561e-04,\n",
       "        1.11890929e-02,  8.86316039e-03,  7.95417174e-04, -2.27385964e-02,\n",
       "       -5.19879628e-03, -2.42456663e-02,  2.16080155e-02, -3.63147296e-02,\n",
       "        4.54790033e-02, -2.93265730e-02,  5.99413514e-02, -8.03930461e-02,\n",
       "        1.67803857e-02, -4.62526754e-02,  6.49676621e-02, -2.35206950e-02,\n",
       "       -1.11728394e-02, -5.37333600e-02, -4.54513989e-02,  1.79062597e-02,\n",
       "        3.65451764e-04, -6.73567131e-02, -2.40356792e-02,  6.25894666e-02,\n",
       "        3.03251762e-02,  4.99337874e-02, -2.88199671e-02, -5.18091470e-02,\n",
       "        8.87285080e-03, -1.12699224e-02, -1.00612752e-02,  4.61505465e-02,\n",
       "        1.75573323e-02, -3.33363824e-02,  2.46172454e-02, -2.78929137e-02,\n",
       "        9.14634988e-02, -4.53075469e-02, -7.69968098e-03, -9.48581658e-03,\n",
       "       -1.41590592e-02,  8.03970359e-03, -2.88099516e-02,  2.29660701e-02,\n",
       "       -9.70076537e-04,  3.34079117e-02,  3.88463549e-02,  1.28135197e-02,\n",
       "        2.10268646e-02,  4.23169602e-03,  5.17750084e-02,  3.36292014e-02,\n",
       "       -1.68754999e-02, -2.47618798e-02,  1.39065394e-02, -8.29100758e-02,\n",
       "        5.74024487e-03, -6.97111785e-02, -4.89856452e-02,  1.97771145e-03,\n",
       "        5.64083550e-03, -1.13669578e-02,  4.99054231e-02, -2.95784064e-02,\n",
       "        2.71689118e-04,  1.47301899e-02, -3.70167047e-02, -8.07050895e-03,\n",
       "       -1.20694400e-03,  3.02218888e-02, -6.58515841e-04, -2.64600329e-02,\n",
       "       -1.45793073e-02, -4.28868793e-02,  2.77065672e-02,  2.91403066e-02,\n",
       "       -4.42281179e-02,  8.76170117e-03,  1.12522598e-02, -5.33943176e-02,\n",
       "       -4.20472622e-02, -5.16729839e-02, -2.17654146e-02,  4.36397865e-02,\n",
       "        5.00044459e-03, -2.44370252e-02,  5.07943071e-02,  4.13213000e-02,\n",
       "        9.58163198e-03,  2.50011892e-03, -4.81071100e-02, -8.27135332e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see a sample vector for random word, lets say Corona \n",
    "w2v_model[\"corona\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7744d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tehran', 0.8465368151664734),\n",
       " ('iranian', 0.7735916376113892),\n",
       " ('destabilizing', 0.6384572982788086),\n",
       " ('hezbollah', 0.6261587738990784),\n",
       " ('sanction', 0.5779509544372559),\n",
       " ('jcpoa', 0.5692330598831177),\n",
       " ('nuke', 0.5665336847305298),\n",
       " ('turkey', 0.5646256804466248),\n",
       " ('ankara', 0.5613735914230347),\n",
       " ('israel', 0.5593534708023071)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"iran\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef1ae060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('comey', 0.7384006381034851),\n",
       " ('cia', 0.6331489086151123),\n",
       " ('investigator', 0.5936321020126343),\n",
       " ('investigation', 0.5773916840553284),\n",
       " ('mueller', 0.5665577054023743),\n",
       " ('doj', 0.5551398992538452),\n",
       " ('classified', 0.522101640701294),\n",
       " ('nsa', 0.513917863368988),\n",
       " ('wiretap', 0.5097992420196533),\n",
       " ('probe', 0.5093430876731873)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"fbi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89cdad5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reddit', 0.6640375256538391),\n",
       " ('instagram', 0.6495581865310669),\n",
       " ('fb', 0.6468603610992432),\n",
       " ('gofundme', 0.6439164280891418),\n",
       " ('google', 0.6190957427024841),\n",
       " ('advert', 0.6006959080696106),\n",
       " ('online', 0.5806050300598145),\n",
       " ('blog', 0.5801248550415039),\n",
       " ('linkedin', 0.5664689540863037),\n",
       " ('website', 0.5535643100738525)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"facebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd370f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('malware', 0.7610825300216675),\n",
       " ('laptop', 0.7521571516990662),\n",
       " ('electronic', 0.7351430654525757),\n",
       " ('software', 0.7296757102012634),\n",
       " ('hacker', 0.7105481028556824),\n",
       " ('device', 0.6972883939743042),\n",
       " ('password', 0.6678939461708069),\n",
       " ('kaspersky', 0.6670196056365967),\n",
       " ('scanning', 0.6613163352012634),\n",
       " ('server', 0.6594116687774658)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "745616c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bush', 0.5362132787704468),\n",
       " ('macron', 0.5202465653419495),\n",
       " ('cruz', 0.5164587497711182),\n",
       " ('hillary', 0.5115461349487305),\n",
       " ('rubio', 0.47204822301864624),\n",
       " ('elect', 0.4702662229537964),\n",
       " ('amateur', 0.4649658799171448),\n",
       " ('conway', 0.4574367105960846),\n",
       " ('penny', 0.453914999961853),\n",
       " ('putin', 0.45359718799591064)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feeding US Presidents\n",
    "w2v_model.wv.most_similar(positive=[\"biden\",\"trump\",\"obama\", \"clinton\"])\n",
    "#First was Bush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d241d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing Text -> Repsesenting each word by a number\n",
    "# Mapping of orginal word to number is preserved in word_index property of tokenizer\n",
    "\n",
    "#Tokenized applies basic processing like changing it yo lower case, explicitely setting that as False\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8c84e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[382, 367, 13376, 2484, 4556, 1272, 4339, 125, 382, 367]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the first 10 words of first news\n",
    "#every word has been represented with a number\n",
    "X[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c8ede3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump -> 1\n",
      "said -> 2\n",
      "state -> 3\n",
      "president -> 4\n",
      "would -> 5\n",
      "people -> 6\n",
      "year -> 7\n",
      "republican -> 8\n",
      "one -> 9\n",
      "news -> 10\n"
     ]
    }
   ],
   "source": [
    "#Lets check few word to numerical replesentation\n",
    "#Mapping is preserved in dictionary -> word_index property of instance\n",
    "word_index = tokenizer.word_index\n",
    "for word, num in word_index.items():\n",
    "    print(f\"{word} -> {num}\")\n",
    "    if num == 10:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "281e52db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For determining size of input...\n",
    "\n",
    "# Making histogram for no of words in news shows that most news article are under 700 words.\n",
    "# Lets keep each news small and truncate all news to 700 while tokenizing\n",
    "plt.hist([len(x) for x in X], bins=500)\n",
    "plt.show()\n",
    "\n",
    "# Its heavily skewed. There are news with 5000 words? Lets truncate these outliers :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "688d0f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44008"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos = np.array([len(x) for x in X])\n",
    "len(nos[nos  < 700])\n",
    "# Out of 48k news, 44k have less than 700 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74796126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets keep all news to 700, add padding to news with less than 700 words and truncating long ones\n",
    "maxlen = 700 \n",
    "\n",
    "#Making all news of size maxlen defined above\n",
    "X = pad_sequences(X, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cf2b8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all news has 700 words (in numerical form now). If they had less words, they have been padded with 0\n",
    "# 0 is not associated to any word, as mapping of words started from 1\n",
    "# 0 will also be used later, if unknows word is encountered in test set\n",
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51d24f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 1 because of reserved 0 index\n",
    "# Embedding Layer creates one more vector for \"UNKNOWN\" words, or padded words (0s). This Vector is filled with zeros.\n",
    "# Thus our vocab size inceeases by 1\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "add12f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create weight matrix from word2vec gensim model\n",
    "def get_weight_matrix(model, vocab):\n",
    "    # total vocabulary size plus 0 for unknown words\n",
    "    vocab_size = len(vocab) + 1\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    for word, i in vocab.items():\n",
    "        weight_matrix[i] = model[word]\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddd7e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting embedding vectors from word2vec and usings it as weights of non-trainable keras embedding layer\n",
    "embedding_vectors = get_weight_matrix(w2v_model, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c51646f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 10\n",
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbe183d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c7e99d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "#Defining Neural Network\n",
    "model = Sequential()\n",
    "#Non-trainable embeddidng layer\n",
    "model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=maxlen, trainable=False))\n",
    "#LSTM \n",
    "model.add(LSTM(units=128 , return_sequences = True , recurrent_dropout = 0.25 , dropout = 0.25))\n",
    "model.add(LSTM(units=64 , recurrent_dropout = 0.1 , dropout = 0.1))\n",
    "model.add(Dense(units = 32 , activation = 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "del embedding_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e77e031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 700, 100)          11068900  \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 700, 128)          117248    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,237,669\n",
      "Trainable params: 168,769\n",
      "Non-trainable params: 11,068,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "049a8e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18df6ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 983s 7s/step - loss: 0.1515 - accuracy: 0.9435 - val_loss: 0.0828 - val_accuracy: 0.9771 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 1006s 8s/step - loss: 0.0402 - accuracy: 0.9873 - val_loss: 0.0090 - val_accuracy: 0.9976 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 1017s 8s/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.0090 - val_accuracy: 0.9976 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9956\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "132/132 [==============================] - 1009s 8s/step - loss: 0.0193 - accuracy: 0.9956 - val_loss: 0.0101 - val_accuracy: 0.9975 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 1086s 8s/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0061 - val_accuracy: 0.9982 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 1074s 8s/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0053 - val_accuracy: 0.9983 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 1121s 8s/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0053 - val_accuracy: 0.9984 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      " 52/132 [==========>...................] - ETA: 12:27 - loss: 0.0043 - accuracy: 0.9990"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = batch_size , validation_data = (X_test,y_test) , epochs = epochs , callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b8e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf376fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of the model on Training Data is - \" , model.evaluate(x_train,y_train)[1]*100 , \"%\")\n",
    "print(\"Accuracy of the model on Testing Data is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a153ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(10)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "fig.set_size_inches(20,10)\n",
    "\n",
    "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
    "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Testing Accuracy')\n",
    "ax[0].set_title('Training & Testing Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax[1].plot(epochs , train_loss , 'go-' , label = 'Training Loss')\n",
    "ax[1].plot(epochs , val_loss , 'ro-' , label = 'Testing Loss')\n",
    "ax[1].set_title('Training & Testing Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(X_test)\n",
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e86bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred, target_names = ['Fake','Not Fake']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15824c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.DataFrame(cm , index = ['Fake','Original'] , columns = ['Fake','Original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9274e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' , xticklabels = ['Fake','Original'] , yticklabels = ['Fake','Original'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca260aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
